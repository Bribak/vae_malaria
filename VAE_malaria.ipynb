{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VAE_malaria.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"LPpEKJgePc1j","colab_type":"code","outputId":"713ce98f-a647-40ed-90ce-ff95e0ef7e57","executionInfo":{"status":"ok","timestamp":1554318255292,"user_tz":-120,"elapsed":2014,"user":{"displayName":"Daniel Bojar","photoUrl":"","userId":"10339697633531698497"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline  \n","from google.colab import drive\n","drive.mount('/content/drive')\n","import torch\n","from torch import nn, optim\n","from torch.nn import functional as F\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image\n","import cv2\n","import glob"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"IEvWjYV2IAGZ","colab_type":"code","colab":{}},"cell_type":"code","source":["#change the URL if necessary; might take a while to get the images so pickle them afterwards (much faster to retrieve)\n","\n","#images = [cv2.imread(file) for file in glob.glob(\"drive/My Drive/Parasitized/*.png\")]\n","#images2 = [cv2.imread(file) for file in glob.glob(\"drive/My Drive/results/Uninfected/*.png\")]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qXlgEzQVtf1F","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","#with open('drive/My Drive/images.pkl','wb') as f:\n","#  pickle.dump(images,f)\n","with open('drive/My Drive/images.pkl','rb') as f:\n","  images=pickle.load(f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PSbiA8o2yQZo","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","#with open('drive/My Drive/images2.pkl','wb') as f:\n","#  pickle.dump(images2,f)\n","with open('drive/My Drive/images2.pkl','rb') as f:\n","  images2=pickle.load(f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MLfFZeU3c6dX","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.utils.data as data\n","\n","class ImageFileset(data.Dataset):\n","  def __init__(self, flist, transform=None):\n","    self.imlist = flist\n","    self.transform = transform\n","    \n","  def __getitem__(self, index):\n","    img = self.imlist[index]\n","    if self.transform is not None:\n","      img = self.transform(img)\n","      \n","    return img\n","  \n","  def __len__(self):\n","    return len(self.imlist)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gwIG5onvcx1Z","colab_type":"code","colab":{}},"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize(size=(128,128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.42983678, 0.39725652, 0.52416897), (0.28184757, 0.26598915, 0.34225056))\n","])\n","\n","trainset=ImageFileset(images,transform=transform)\n","train_loader = torch.utils.data.DataLoader(trainset,batch_size=128, shuffle=True)\n","\n","trainset_control=ImageFileset(images2,transform=transform)\n","train_loader_control = torch.utils.data.DataLoader(trainset_control,batch_size=128, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8BpO2--KuP7o","colab_type":"code","colab":{}},"cell_type":"code","source":["class VAE(nn.Module):\n","    def __init__(self):\n","        super(VAE, self).__init__()\n","\n","        #3*128*128=49152\n","        self.fc1 = nn.Linear(49152, 400)\n","        self.fc1_bn = nn.BatchNorm1d(400)\n","        self.fc21 = nn.Linear(400, 20)\n","        self.fc22 = nn.Linear(400, 20)\n","        self.fc3 = nn.Linear(20, 400)\n","        self.fc3_bn = nn.BatchNorm1d(400)\n","        self.fc4 = nn.Linear(400, 49152)\n","\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1_bn(self.fc1(x)))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5*logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps*std\n","\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3_bn(self.fc3(z)))\n","        return torch.sigmoid(self.fc4(h3))\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x.view(-1, 49152))\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6zJ-Wj68Hr7c","colab_type":"code","colab":{}},"cell_type":"code","source":["#Xavier initialization\n","def init_weights(m):\n","    if type(m) == nn.Linear:\n","        torch.nn.init.xavier_uniform_(m.weight)\n","        m.bias.data.fill_(0.01)\n","        \n","import math  \n","#Kaiming initialization\n","def kaiming_init(m):\n","    if type(m) == nn.Linear:\n","      weights,bias = m.named_parameters()\n","      m.weight = torch.nn.Parameter(torch.randn(weights[1].shape[0],weights[1].shape[1])*math.sqrt(2./weights[1].shape[0]))\n","      m.bias.data.fill_(0)\n","        \n","model=VAE()\n","model.apply(kaiming_init)\n","model.cuda()\n","optimizer=optim.Adam(model.parameters(),lr=1e-4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yiwhzdcAJN3e","colab_type":"code","colab":{}},"cell_type":"code","source":["# Reconstruction + KL divergence losses summed over all elements and batch\n","def loss_function(recon_x, x, mu, logvar, epoch):\n","    #binary cross-entropy\n","    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 49152))\n","    #Kullback-Leibler divergence\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","\n","    return BCE + 0.1*KLD\n","\n","def adjust_learning_rate(optimizer, epoch,lr):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 2 every 1 epochs\"\"\"\n","    lr = lr * (0.5 ** (epoch // 1))\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_X9uNG4eJexK","colab_type":"code","colab":{}},"cell_type":"code","source":["def train(epoch):\n","    model.train()\n","    train_loss = 0\n","    #change to train_loader_control for noninfected cells\n","    for batch_idx, val in enumerate(train_loader):\n","        adjust_learning_rate(optimizer,epoch-1,optimizer.param_groups[0]['lr'])\n","        val = val.cuda()\n","        optimizer.zero_grad()\n","        recon_batch, mu, logvar = model(val)\n","        loss = loss_function(recon_batch, val, mu, logvar, epoch)\n","        loss.backward()\n","        train_loss += loss.item()\n","        optimizer.step()\n","        if batch_idx % 5 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(val), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader),\n","                loss.item() / len(val)))\n","\n","    print('====> Epoch: {} Average loss: {:.4f}'.format(\n","        epoch, train_loss / len(train_loader.dataset)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-v9RGntCJ5fy","colab_type":"code","colab":{}},"cell_type":"code","source":["for epoch in range(1, 11):\n","        train(epoch)\n","        if epoch % 2 == 0:\n","          with torch.no_grad():\n","              sample = torch.randn(64, 20).cuda()\n","              sample = model.decode(sample)\n","              save_image(sample.view(64, 3, 128, 128),\n","                'drive/My Drive/results/sample_' + str(epoch) + '.png')"],"execution_count":0,"outputs":[]}]}